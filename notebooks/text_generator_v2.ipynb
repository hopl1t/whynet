{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer_style_onehot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M7DQ-kO90os",
        "outputId": "71dd68b3-40ac-46d6-ee76-811145832d04"
      },
      "source": [
        "!pip install -U torchtext==0.8.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/8a/e09b9b82d4dd676f17aa681003a7533765346744391966dec0d5dba03ee4/torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.7.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.7.4.3)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ5YrOi79-Xu",
        "outputId": "fbbd0756-11db-4001-f4b7-2a2f38574de6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Mar  3 18:05:46 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNHW7qZ-9_iY"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "from torchtext.utils import download_from_url, extract_archive\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import time\n",
        "import re\n",
        "import fileinput\n",
        "import pickle\n",
        "import time\n",
        "from torchtext import datasets\n",
        "import torchtext\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua7i9gbWIC39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b16eee2-7d6d-440f-880b-0726362c8abd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('drive/MyDrive/Colab Notebooks/nn_project')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5T0ougd-C83"
      },
      "source": [
        "PICKLE_PATH = 'data/ynet_data.pkl'\n",
        "MAX_LEN = 512\n",
        "# Back Propogation Through Time\n",
        "BPTT = 512\n",
        "BATCH_SIZE = 12\n",
        "EVAL_BATCH_SIZE = 6\n",
        "EOS = '[EOS]'\n",
        "SPECIAL_TOKENS = ['[SOS]', '[SUB]', '[EOS]', '[SEC]', '[UNK]'\\\n",
        "                  '[PAD]', '[UNK]', '[SEP]', '[SEP1]', '[SEP2]']\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")                  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b251mPvd-MbS"
      },
      "source": [
        "def char_tokenizer(text, special_tokens = SPECIAL_TOKENS):\n",
        "    \"\"\"\n",
        "    TODO: ignore special chars - decrease vocab size\n",
        "    Generator\n",
        "    tokenizes text to chars, expcet for special tokens\n",
        "    \"\"\"\n",
        "    for word in text.split():\n",
        "        if word in special_tokens:\n",
        "            yield word\n",
        "        else:\n",
        "            for char in word:\n",
        "                yield char\n",
        "            yield ' '\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Injects some information about the relative or absolute position of the\n",
        "    tokens in the sequence. The positional encodings have the same dimension as\n",
        "    the embeddings so that the two can be summed. Here, we use sine and cosine \n",
        "    functions of different frequencies.\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        # pe = positional encoding. Buffer = data that is not a model parameter but kept anyway\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)            \n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5,\\\n",
        "                 num_meta=10, num_classes=12, min_time=1, max_time=2203):\n",
        "        \"\"\"\n",
        "        Encoder only transformer (like Bert)\n",
        "        :param ntoken - int: size of the dictionary of embeddings (num_embeddings)\n",
        "        :param ninp: the number of expected features in the input (d_model). total size of embedding\n",
        "        :param nhead: the number of heads in the multiheadattention models\n",
        "        :param nhid: the dimension of the feedforward network model (torch default 2048)\n",
        "        :param nlayers: number of encoder layers\n",
        "        :param dropout: float, probability for dropout of a neuron\n",
        "        \"\"\"\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(ninp - num_meta, dropout)\n",
        "        self.num_classes = num_classes\n",
        "        self.min_time = min_time\n",
        "        self.max_time = max_time\n",
        "        self.loss_list = []\n",
        "        self.meta1_encoder = nn.Linear(self.num_classes, 5, bias=False)\n",
        "        self.meta2_encoder = nn.Linear(1, 5, bias=False)\n",
        "        # self-attn and feedforward network.\n",
        "        # This standard encoder layer is based on the paper \"Attention Is All You Need\".\n",
        "        # This has multiheaded_attention + add&norm + pointwise feed_forward (entire left encoder part)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        \n",
        "        # TransformerEncoder is a stack of N encoder layers\n",
        "        # This is the encoder only alot of stack for better encoding - this is the actual layer used\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        \n",
        "        # A simple lookup table that stores embeddings of a fixed dictionary and size\n",
        "        self.encoder = nn.Embedding(ntoken, ninp - num_meta) # -10 because we add two meta entries manually\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        \"\"\"\n",
        "        A square attention mask is required because the self-attention layers \n",
        "        in nn.TransformerEncoder are only allowed to attend the earlier \n",
        "        positions in the sequence. For the language modeling task, any tokens on\n",
        "        the future positions should be masked.\n",
        "        :param sz - : size?\n",
        "        \"\"\"\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.meta1_encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.meta2_encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, data, src_mask):\n",
        "        # Embedding\n",
        "        src = data[:,:,0] # these are the letter tokens\n",
        "        meta1 = data[:,:,1]  #/ self.num_classes # labels, scaled down by num classes\n",
        "        # timestamp + min-max normalization\n",
        "        meta2 = data[:,:,2] #(data[:,:,2] - self.min_time) / (self.max_time - self.min_time) \n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        # Injects some information about the relative or absolute position of the tokens in the sequence\n",
        "        src = self.pos_encoder(src)\n",
        "        # Concat meta data as two single entries in the embedded state (no pos embedding)\n",
        "        meta1 = F.one_hot(meta1, self.num_classes) \n",
        "        meta1 = self.meta1_encoder(meta1.float())\n",
        "        meta2 = self.meta2_encoder(meta2.unsqueeze(2).float())\n",
        "        src = torch.cat((src, meta1), 2)\n",
        "        src = torch.cat((src, meta2), 2)\n",
        "        # multi-head transformer\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        # fully connected linear\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "def data_process(data_iter, meta1_iter, meta2_iter):\n",
        "    \"\"\"\n",
        "    Processes data and 2 metadata fileds\n",
        "    First two entries for each item will be the meta entries (needs to be split in forward logic)\n",
        "    \"\"\"\n",
        "    processed = torch.zeros((len(data_iter), MAX_LEN, 3), dtype=torch.long)\n",
        "    for idx, (string, meta1, meta2) in enumerate(zip(data_iter, meta1_iter, meta2_iter)):\n",
        "        tokenized = [vocab[token] for token in tokenizer(string)]\n",
        "        if len(tokenized) < MAX_LEN:\n",
        "            tokenized += ([vocab.stoi['[PAD]']] * (MAX_LEN - len(tokenized)))\n",
        "        processed[idx][:,0] = torch.tensor(tokenized, dtype=torch.long)\n",
        "        processed[idx][:,1] = torch.tensor(meta1, dtype=torch.long)\n",
        "        processed[idx][:,2] = torch.tensor(meta2, dtype=torch.long)\n",
        "        \n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, processed)))\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    # Divide the dataset into bsz parts. (bsz = batch size)\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "#     data = data.view(bsz, -1).t().contiguous()\n",
        "    data = torch.transpose(data.view(bsz, -1, 3), 0, 1).contiguous()\n",
        "#     yield data.to(device)\n",
        "    return data.to(device)\n",
        "\n",
        "def get_batch(source, i):\n",
        "    \"\"\"\n",
        "    Generates the input and target sequence for the transformer model. \n",
        "    It subdivides the source data into chunks of length BPTT. \n",
        "    For the language modeling task, the model needs the following words \n",
        "    as Target.\n",
        "    \"\"\"\n",
        "    seq_len = min(BPTT, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    # this is a good fix, even for alter when we use style transfer.\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)[::3]\n",
        "    return data, target\n",
        "\n",
        "def train():\n",
        "    \"\"\"\n",
        "    Trains one epoch - stochastic GD over an entire batch\n",
        "    StepLR is applied to adjust the learn rate through epochs. \n",
        "    During the training, we use nn.utils.clip_grad_norm_ function to scale \n",
        "    all the gradient together to prevent exploding.\n",
        "    \"\"\"\n",
        "    model.train() # Turn on the train mode\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    # A square attention mask is required because the self-attention layers \n",
        "    # in nn.TransformerEncoder are only allowed to attend the earlier \n",
        "    # positions in the sequence.\n",
        "    src_mask = model.generate_square_subsequent_mask(BPTT).to(device)\n",
        "    for batch, i in enumerate(range(0, train_data_post.size(0) - 1, BPTT)):\n",
        "        data, targets = get_batch(train_data_post, i)\n",
        "        optimizer.zero_grad()\n",
        "        # source data into chunks of length BPTT\n",
        "        if data.size(0) != BPTT:\n",
        "            # src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            print('got batch of size {0}, skipping'.format(data.shape))\n",
        "            continue\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        log_interval = 200\n",
        "        save_interval = 2000\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                    epoch, batch, len(train_data_post) // BPTT, scheduler.get_lr()[0],\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    cur_loss, math.exp(cur_loss)))\n",
        "            model.loss_list.append(cur_loss)\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "        if batch % save_interval == 0 and batch > 0:\n",
        "            # v2 because we fear overfiting\n",
        "            with open('saved_models/heb_char_model_onehot_v2.pkl', 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            print('saved model')\n",
        "\n",
        "def evaluate(eval_model, data_source):\n",
        "    eval_model.eval() # Turn on the evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = model.generate_square_subsequent_mask(BPTT).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, BPTT):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            if data.size(0) != BPTT:\n",
        "                # src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "                print('skipping sample eval because of shape: {0}'.format(data.shape))\n",
        "                continue\n",
        "            output = eval_model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)    \n",
        "\n",
        "def predict(X):\n",
        "  \"\"\"\n",
        "  Recives unactivated output as 2D tensor \n",
        "  Predicts classes\n",
        "  \"\"\"\n",
        "  activated = torch.softmax(X, dim=1)\n",
        "  _, prediction = torch.max(activated, 1)\n",
        "  return prediction\n",
        "  \n",
        "def generate(model, vocab, start_string, genre, timestamp, temperature, max_len):\n",
        "    '''\n",
        "    This function gets a trained model and vocab and generates a random string\n",
        "    using the model, seeded with the start_string string.\n",
        "    The temparature value is used to generate a more diverse output (high value),\n",
        "    then a conservative one (low value).\n",
        "    '''\n",
        "        \n",
        "    # remove the EOS, we don't need it for generation\n",
        "    # TODO: ADD EOS TO DATA\n",
        "    # sequence = sequence[:-1]\n",
        "    \n",
        "    model.eval()\n",
        "    words = [w for w in tokenizer(start_string)]\n",
        "    \n",
        "    for i in range(max_len):\n",
        "        sequence = vocab.lookup_indices(words)\n",
        "        sequence_ten = torch.LongTensor(sequence)\n",
        "        length = sequence_ten.shape[0]\n",
        "        expanded = torch.stack((sequence_ten, torch.tensor([genre]*length),\\\n",
        "                            torch.tensor([timestamp]*length)), 1)\n",
        "        src_mask = model.generate_square_subsequent_mask(len(sequence)).to(device)\n",
        "        forward = model(expanded.unsqueeze(1).to(device), src_mask)\n",
        "        prediction = predict(forward[-1])\n",
        "        next_word = vocab.itos[prediction]\n",
        "        if next_word == EOS:\n",
        "            i = max_len + 1\n",
        "        else:\n",
        "            words.append(next_word)\n",
        "    return words"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE9T0Amv_VCF",
        "outputId": "2659fcff-57ee-4b4a-e8df-43effa56cc7f"
      },
      "source": [
        "data = pd.read_pickle(PICKLE_PATH)\n",
        "label_dict = {key: value for value, key in enumerate(data.label.unique())}\n",
        "\n",
        "train_len = int(len(data) * 0.9)\n",
        "train_data = data[0:train_len]\n",
        "val_data = data[train_len:]\n",
        "\n",
        "tokenizer = char_tokenizer\n",
        "vocab = build_vocab_from_iterator(map(tokenizer,\n",
        "                                      train_data['data'].__iter__()))\n",
        "\n",
        "# Conform vocab to Bert standarts\n",
        "# vocab.itos[0] = '[UNK]'\n",
        "# vocab.itos[1] = '[PAD]'\n",
        "# vocab.stoi['[UNK]'] = 0\n",
        "# vocab.stoi['[PAD]'] = 1\n",
        "# vocab.stoi.pop('<pad>')\n",
        "# vocab.stoi.pop('<unk>')\n",
        "# vocab.UNK = '[UNK]'\n",
        "\n",
        "train_text_data = train_data['data']\n",
        "train_label_data = train_data['label_num']\n",
        "train_time_data = train_data['date'] - 2e5\n",
        "\n",
        "val_text_data = val_data['data']\n",
        "val_label_data = val_data['label_num']\n",
        "val_time_data = val_data['date'] - 2e5\n",
        "\n",
        "train_data_pre = data_process(train_text_data,\\\n",
        "                              train_label_data, train_time_data)\n",
        "val_data_pre = data_process(val_text_data,\\\n",
        "                            val_label_data, val_time_data)\n",
        "\n",
        "train_data_post = batchify(train_data_pre, BATCH_SIZE)\n",
        "val_data_post = batchify(val_data_pre, EVAL_BATCH_SIZE)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "237033lines [00:25, 9184.16lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPolcV1i_Z9c",
        "outputId": "fba11a5b-4cb5-445d-b452-77b2ac6ac8ca"
      },
      "source": [
        "# sanity check\n",
        "[vocab.itos[int(c)] for c in train_data_post[0:10][:,0][:,0]]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[SOS]', 'צ', 'ה', '\"', 'ל', ' ', 'א', 'י', 'ת', 'ר']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNYY0cYHABBE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "01edff8c-47d5-42e1-afaa-a3428e156a55"
      },
      "source": [
        "ntokens = len(vocab.stoi) # the size of vocabulary\n",
        "emsize = 768 # embedding dimension - 768 like in BERT\n",
        "nhid = 3072 # the dimension of the feedforward network model in nn.TransformerEncoder - 3072 like in BERT\n",
        "nlayers = 12 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder - we put 12 like in BERT\n",
        "nhead = 12 # the number of heads in the multiheadattention models - we put 12 like in BERT\n",
        "dropout = 0.1 # the dropout value - 0.1 like in BERT\n",
        "# model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)\n",
        "model = torch.load('saved_models/heb_char_model_onehot_v2.pkl')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0f0d83f96f39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mntokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# the size of vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0memsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m768\u001b[0m \u001b[0;31m# embedding dimension - 768 like in BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnhid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3072\u001b[0m \u001b[0;31m# the dimension of the feedforward network model in nn.TransformerEncoder - 3072 like in BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;31m# the number of nn.TransformerEncoderLayer in nn.TransformerEncoder - we put 12 like in BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;31m# the number of heads in the multiheadattention models - we put 12 like in BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYfT2eN9_aaw"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# lr = 5e-5 # learning rate\n",
        "lr = 3e-5 # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgJKoJj7_ald",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42fdf693-2efe-4935-aa8d-e1faa4770526"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "# del variables\n",
        "gc.collect()  "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2276"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMuvJxYh_atO"
      },
      "source": [
        "%%time\n",
        "best_val_loss = float(\"inf\")\n",
        "epochs = 40 # The number of epochs\n",
        "best_model = None\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train()\n",
        "    val_loss = evaluate(model, val_data_post)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                     val_loss, math.exp(val_loss)))\n",
        "    print('-' * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = model\n",
        "        with open('heb_char_model.pkl', 'wb') as f:\n",
        "            torch.save(model, f)\n",
        "\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdg29s5iXw79"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqKWDWLf_a7j",
        "outputId": "40296701-5acb-45a8-c548-214ad7cd5c14"
      },
      "source": [
        "model.eval() # Turn on the evaluation mode\n",
        "\n",
        "# ['צבאי', 'משפט ופלילי', 'בריאות וחינוך', 'כלכלה עולמית', 'כללי', 'פוליטי'\n",
        "# 'כלכלה ישראל', 'כדורגל', 'פלסטינים', 'סקס', 'סקס ויחסים', ';כלכלה עולמית']\n",
        "genre = label_dict['כללי']\n",
        "timestamp = 1000\n",
        "\n",
        "start_string = \"\"\"עזר\"\"\"\n",
        "# start_string = \"\"\"איש העסקים האמריקאי\"\"\"\n",
        "# start_string = \"\"\"שר הכדורגל ויו\"ר התאגדות המנופאים\"\"\"\n",
        "# start_string = \"\"\"איך תדעי אם השותף שלך אוהב אותך?\"\"\"\n",
        "# start_string = \"\"\" תושב כפר סבא חשוד כי סחר בחמוסים\"\"\"\n",
        "# start_string = \"\"\"[SOS] מחסור בחמאה בעקבות שביתה בנמל [SEP1] ברחבי הארץ הורגש מחסור חמור בחמאה לקראת חג הפסח [SEP2] \"\"\"\n",
        "# start_string = \"\"\"הרשות הפלסטינית תחלק ממתקים למתנחלים לכבוד פסח\"\"\"\n",
        "# start_string = '[SOS] ' + start_string\n",
        "# start_string = '[SOS] ' + start_string + ' [SEP1]'\n",
        "\n",
        "\n",
        "generated_text = ''\n",
        "with torch.no_grad():\n",
        "    generated = generate(model, vocab, start_string, genre, timestamp, 1, 500)\n",
        "for char in generated:\n",
        "    generated_text += char\n",
        "print(generated_text)\n",
        "print(' ')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "עזר במיוחד לאחר שהורשע בהריגת הנער במסעדה בירושלים במסעדה בירושלים. הוא הורשע בהריגת הנער במסעדה בירושלים במסעדה בירושלים. הנער הורשע בהריגת הנער במסעדה בירושלים במסעדה בירושלים. הנער הורשע בהריגת הנער במסעדה בירושלים במסעדה בירושלים. הנער הו \n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPDQjwPhO6El"
      },
      "source": [
        "genres = data.label.unique()\n",
        "generated_articles = []"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YImZEZsO6s8"
      },
      "source": [
        "start_string_list = [\n",
        "                     \"\"\"ראש הממשלה\"\"\",\n",
        "                     \"\"\"נתינהו:\"\"\",\n",
        "                     \"\"\"שר הבריאות\"\"\",\n",
        "                     \"\"\"גאווה ישראלית\"\"\",\n",
        "                     \"\"\"משואה לתקומה\"\"\",\n",
        "                     \"\"\"הישג אדיר\"\"\",\n",
        "                     \"\"\"התפתחות מפתיעה\"\"\",\n",
        "                     \"\"\"מועצת החכמים\"\"\",\n",
        "                     \"\"\"איגוד יצרני\"\"\",\n",
        "                     \"\"\"מפכ\"ל המשטרה:\"\"\",\n",
        "                     \"\"\"שר הביטחון:\"\"\",\n",
        "                     \"\"\"ירידות חדות\"\"\",\n",
        "                     \"\"\"זינוק\"\"\",\n",
        "                     \"\"\"נשיא המדינה\"\"\",\n",
        "                     \"\"\"השרים אישרו\"\"\",\n",
        "                     \"\"\"הקבינט התכנס\"\"\",\n",
        "                     \"\"\"מה קרה\"\"\",\n",
        "                     \"\"\"מי גנב\"\"\",\n",
        "                     \"\"\"מה קורה\"\"\",\n",
        "                     \"\"\"אלף ימים\"\"\",\n",
        "                     \"\"\"עלייתו ונפילתו\"\"\",\n",
        "                     \"\"\"אזהרה: \"\"\",\n",
        "                     \"\"\"אין גבול\"\"\",\n",
        "                     \"\"\"המלחמה נמשכת:\"\"\",\n",
        "                     \"\"\"דווקא אחרי\"\"\",\n",
        "                     \"\"\"ראש המל\"ל\"\"\",\n",
        "                     \"\"\"עשרות חמוסים\"\"\",\n",
        "                     \"\"\"קרב צמוד בין\"\"\",\n",
        "                     \"\"\"תגלית מפתיעה\"\"\",\n",
        "]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1ottO2J3ex2y",
        "outputId": "c1f54619-d724-4c34-f4ff-09ffbcb6e95f"
      },
      "source": [
        "a = \"\"\"בלה בלה ynet בלה\"\"\"\n",
        "a.replace('ynet', 'whynet')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'בלה בלה whynet בלה'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jal2YDPZO6za",
        "outputId": "2c831bd3-ee8f-4e7a-be31-e1ec0f2a12c6"
      },
      "source": [
        "%%time\n",
        "generated_articles = []\n",
        "for start_string in start_string_list:\n",
        "    start_string = '[SOS] ' + start_string\n",
        "    for label in genres:\n",
        "        genre = label_dict[label]\n",
        "        year = random.randint(0,21) * 100\n",
        "        month = random.randint(0,12)\n",
        "        day = random.randint(0,29)\n",
        "        timestamp = year + month\n",
        "        generated_text = ''\n",
        "        with torch.no_grad():\n",
        "            generated = generate(model, vocab, start_string, genre, timestamp, 1, 512)\n",
        "        for char in generated:\n",
        "            generated_text += char\n",
        "\n",
        "        title = generated_text.split('[SEP1]')[0].strip('[SOS] ')\n",
        "        try:\n",
        "            sub_title = generated_text.split('[SEP1]')[1].split('[SEP2]')[0].strip('[SEP1] ')\n",
        "        except IndexError:\n",
        "            sub_title = ''\n",
        "        try:\n",
        "            body = generated_text.split('[SEP1]')[1].split('[SEP2]')[1].strip('[SEP2]')\n",
        "        except IndexError:\n",
        "            body = ''\n",
        "\n",
        "        tilte = title.replace('ynet', 'whynet')\n",
        "        sub_tilte = title.replace('ynet', 'whynet')\n",
        "        body = title.replace('ynet', 'whynet')\n",
        "\n",
        "        generated_articles.append((start_string, genre, \"{0}.{1}.{2}\"\\\n",
        "                                   .format(day, month, (year // 100) + 2000) ,\\\n",
        "                                   title, sub_title, body))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1h 29min 30s, sys: 6min 42s, total: 1h 36min 13s\n",
            "Wall time: 50min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hCGhNM5TfQb"
      },
      "source": [
        "new_list = []\n",
        "for i in range(0, len(generated_articles)):\n",
        "    new_list.append([item for item in generated_articles[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "TuoCJjWQU4EC",
        "outputId": "10e4742b-1048-4b2e-837c-f3a3e1a973e3"
      },
      "source": [
        "new_list"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-8a9015be32e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'new_list' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "erR9OeyTR1dp",
        "outputId": "f1901bb6-696f-4fd3-b1da-11e51e80a462"
      },
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "axes[0].set_title('loss per 200 batchs')\n",
        "_ = axes[0].plot(model.loss_list, color='blue', alpha=0.5)\n",
        "axes[1].set_title('perplexity per 200 batchs')\n",
        "_ = axes[1].plot(np.exp(np.array(model.loss_list)), color='blue', alpha=0.5)\n",
        "_ = axes[0].set_xlabel('x200 batchs')\n",
        "_ = axes[0].set_ylabel('loss')\n",
        "_ = axes[1].set_xlabel('x200 batchs')\n",
        "_ = axes[1].set_ylabel('loss')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}